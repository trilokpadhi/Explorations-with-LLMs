This repository contains my experiments with the LLMs related to fine-tuning, prompt-tuning, PEFT and other techniques. The experiments are done on various datasets and the results are compared with the baselines. 



## Structure
`PEFT` - Contains the experiments related to the PEFT technique.
`Prompt-Tuning` - Contains the experiments related to the Prompt-Tuning technique.
`Adapter-Tuning` - Contains the experiments related to the Adapter-Tuning technique.

## Techniques Used

This repository utilizes several techniques for fine-tuning and prompt-tuning of Language Models (LLMs). Here are some of the key techniques used:

1. **PEFT (Parameter Efficient Fine Tuning)**: This technique involves creating effective prompts that guide the model to generate the desired output.
    - **Prompt-Tuning**: This is a method of fine-tuning where the model is trained to respond to specific prompts with specific responses.
    - **Adapter-Tuning**: This technique involves adding and training small, task-specific modules in the model without modifying the pre-trained parameters.

## Datasets

## Models
1. Llama-2
2. Gemma
3. Mistral

## Libraries
1. Huggingface Transformers
2. PyTorch Lightning

## Experiments

## Results


## Resources
- https://github.com/Lightning-AI/litgpt 

